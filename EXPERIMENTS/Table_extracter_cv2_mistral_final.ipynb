{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SpFUpYjeGbS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in ./venv/lib/python3.12/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in ./venv/lib/python3.12/site-packages (from opencv-python-headless) (2.2.3)\n",
            "Requirement already satisfied: pytesseract in ./venv/lib/python3.12/site-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.12/site-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in ./venv/lib/python3.12/site-packages (from pytesseract) (9.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install pytesseract\n",
        "!pip install Pillow\n",
        "!pip install pdf2image\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo6omoFzel98"
      },
      "outputs": [],
      "source": [
        "# !sudo apt-get install poppler-utils\n",
        "# !sudo apt-get install tesseract-ocr\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import os\n",
        "import logging\n",
        "import re\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "# from langchain.document_loaders import UnstructuredPDFLoader\n",
        "import re\n",
        "import json\n",
        "from typing import List,Tuple,Any,Union,Dict\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "data1 = {\"Statement_Consolidated_finanacial_results_for_all_months\": {\n",
        "        \"Quarter ended 31 December 2024\": {\n",
        "            \"Revenue from operations\": 16175.71,\n",
        "            \"Other income\": 1301.15,\n",
        "            \"Total income\": 17476.86,\n",
        "            \"Cost of construction and development\": 6272.52,\n",
        "            \"Changes in inventories of work-in-progress and finished properties\": 1275.2,\n",
        "            \"Employee benefit expense\": 2743.89,\n",
        "            \"Finance costs\": 874.35,\n",
        "            \"Depreciation and amortisation expenses\": 312.6,\n",
        "            \"Other expenses\": 3596.12,\n",
        "            \"Total expenses\": 12524.2,\n",
        "            \"Profit/loss before tax and share of profit/loss of joint ventures\": 4952.66,\n",
        "            \"Share of profit/loss of joint ventures, net\": 11.2,\n",
        "            \"Profit/loss before tax\": 4941.42,\n",
        "            \"Current tax\": 277.46,\n",
        "            \"Deferred tax\": 411.9,\n",
        "            \"Profit/loss for the period/year\": 4252.06,\n",
        "            \"Other comprehensive income/loss\": 473.84,\n",
        "            \"Total comprehensive income/loss for the period/year, net of tax\": 4725.9\n",
        "        },\n",
        "}}\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
        "model = ChatOpenAI(model='gpt-4o')\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X695svACeG7u",
        "outputId": "c03afda1-3ff5-4fbe-b1d2-f9975ccfc61c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TableExtractor:\n",
        "\n",
        "    def __init__(self, pdf_path):\n",
        "        # self.data1 =data1\n",
        "        self.huggingfacehub_api_token = \"YOUR_HUGGINGFACE_API_KEY\"  # Replace with your Hugging Face token\n",
        "        self.repo_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "        # self.llm = HuggingFaceHub(\n",
        "        #     huggingfacehub_api_token=self.huggingfacehub_api_token,\n",
        "        #     repo_id=self.repo_id,\n",
        "        #     model_kwargs={\"temperature\": 0.1, \"max_new_tokens\":3000}\n",
        "        # )\n",
        "        self.llm = model\n",
        "        self.pdf_path = pdf_path\n",
        "\n",
        "    def _image_list_(self, pdf_path: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Converts all pages in a PDF file to images, saving them locally and returning a list of image filenames.\n",
        "\n",
        "        Parameters:\n",
        "        - pdf_path (str): The file path of the PDF document to be converted.\n",
        "\n",
        "        Returns:\n",
        "        - List[str]: A list of filenames for the images created, one per page of the PDF.\n",
        "\n",
        "        Raises:\n",
        "        - Exception: Propagates any exception that occurs during the PDF to image conversion process,\n",
        "                    after logging the error.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            images = convert_from_path(self.pdf_path)\n",
        "            img_list = []\n",
        "            for i, image in enumerate(images):\n",
        "                image_name = f'page_{i}.jpg'\n",
        "                image.save(image_name, 'JPEG')\n",
        "                img_list.append(image_name)\n",
        "            return img_list\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error converting PDF to images: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _preprocess_image_(self, image_path: str) -> Any:\n",
        "      \"\"\"\n",
        "      Preprocesses an image to enhance table detection and OCR accuracy by converting it to grayscale,\n",
        "      applying noise reduction, and performing thresholding to obtain a binary image.\n",
        "\n",
        "      Parameters:\n",
        "      - image_path (str): The file path of the image to preprocess.\n",
        "\n",
        "      Returns:\n",
        "      - Any: The preprocessed image in a binary format suitable for further processing. The actual type\n",
        "            is dependent on the OpenCV version used, but it generally corresponds to a numpy array.\n",
        "\n",
        "      Raises:\n",
        "      - FileNotFoundError: If the specified image file does not exist.\n",
        "      - Exception: For issues related to reading the image or preprocessing steps.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        img = cv2.imread(image_path)\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        # Noise removal\n",
        "        denoised = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
        "        # Thresholding to get a binary image\n",
        "        _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        return thresh\n",
        "\n",
        "      except Exception as e:\n",
        "          logging.error(\"Error during the preprocessing of the image\", exc_info=True)\n",
        "          raise\n",
        "\n",
        "\n",
        "    def _detect_tables_(self, image: Any) -> List[Tuple[int, int, int, int]]:\n",
        "      \"\"\"\n",
        "      Detects tables in an image using morphological transformations for line detection\n",
        "      and contour detection to identify table boundaries.\n",
        "\n",
        "      Parameters:\n",
        "      - image (Any): The preprocessed binary image where tables are to be detected. The type is\n",
        "                    typically a NumPy array, though it is annotated as `Any` to accommodate for\n",
        "                    flexibility in input image types.\n",
        "\n",
        "      Returns:\n",
        "      - List[Tuple[int, int, int, int]]: A list of tuples, each representing the bounding box of a detected\n",
        "                                        table in the format (x, y, width, height).\n",
        "\n",
        "      Note:\n",
        "      This method assumes the input image is preprocessed, ideally binary, to highlight table structures.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        # Use morphological transformations to detect lines\n",
        "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image.shape[0] / 30)))\n",
        "        horiz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image.shape[1] / 30), 1))\n",
        "        vertical_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
        "        horizontal_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, horiz_kernel, iterations=2)\n",
        "\n",
        "        # Combine lines\n",
        "        table_grid = cv2.add(horizontal_lines, vertical_lines)\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(table_grid, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        tables = []\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            if w * h > image.size * 0.001:  # Filter out small contours\n",
        "                tables.append((x, y, w, h))\n",
        "\n",
        "        logging.info(f\"Detected {len(tables)} tables in the image.\")\n",
        "        return tables\n",
        "\n",
        "      except Exception as e:\n",
        "        logging.error(\"Error during table detection\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "\n",
        "    def _extract_text_from_tables_(self, image: Any, tables: List[Tuple[int, int, int, int]]) -> List[str]:\n",
        "      \"\"\"\n",
        "      Extracts text from specified table regions in an image using OCR.\n",
        "\n",
        "      Parameters:\n",
        "      - image (Any): The image from which text is to be extracted. The type is typically a NumPy array,\n",
        "                    though it is annotated as `Any` to accommodate for flexibility in input image types.\n",
        "      - tables (List[Tuple[int, int, int, int]]): A list of tuples, each representing the bounding box\n",
        "                                                  of a table to extract text from, in the format\n",
        "                                                  (x, y, width, height).\n",
        "\n",
        "      Returns:\n",
        "      - List[str]: A list of strings, where each string contains the text extracted from the corresponding\n",
        "                  table region defined in the `tables` parameter.\n",
        "\n",
        "      Raises:\n",
        "      - Exception: For issues during the image cropping or OCR process.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        texts = []\n",
        "        for (x, y, w, h) in tables:\n",
        "            table_image = image[y:y+h, x:x+w]\n",
        "            text = pytesseract.image_to_string(table_image, lang='eng')\n",
        "            texts.append(text)\n",
        "        logging.info(f\"Extracted text from {len(tables)} tables.\")\n",
        "        return texts\n",
        "      except Exception as e:\n",
        "        logging.error(\"Error extracting text from tables\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "\n",
        "    def extract_tables_and_text(self) -> List[str]:\n",
        "      \"\"\"\n",
        "      Extracts tables and their respective text from the document specified by `self.pdf_path`.\n",
        "\n",
        "      This method integrates the workflow of converting PDF pages to images, preprocessing images for table\n",
        "      detection, detecting table boundaries, and extracting text from these tables.\n",
        "\n",
        "      Returns:\n",
        "      - List[str]: A list of strings, each string contains the text extracted from a table detected in the\n",
        "                  document. The list is compiled from all tables detected across all pages of the document.\n",
        "\n",
        "      Raises:\n",
        "      - Exception: For any issues encountered during the processes of image conversion, preprocessing,\n",
        "                  table detection, or text extraction.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        logging.info(\"Starting table and text extraction process.\")\n",
        "        # Convert all pages of the PDF to images and store the paths in `images`.\n",
        "        images = self._image_list_(self.pdf_path)\n",
        "\n",
        "        # Initialize an empty list to hold all extracted texts from tables.\n",
        "        all_tables_text = []\n",
        "\n",
        "        # Iterate through each image path in the list of images.\n",
        "        for image_path in images:\n",
        "            preprocessed_image = self._preprocess_image_(image_path)\n",
        "            tables = self._detect_tables_(preprocessed_image)\n",
        "            texts = self._extract_text_from_tables_(preprocessed_image, tables)\n",
        "            all_tables_text.extend(texts)\n",
        "\n",
        "        logging.info(\"Completed table and text extraction process.\")\n",
        "        # Return the list of extracted texts from all tables.\n",
        "        return all_tables_text\n",
        "      except Exception as e:\n",
        "        logging.error(\"Error in extracting tables and text\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "    def extracted_data(self) -> List[str]:\n",
        "      \"\"\"\n",
        "      Cleans and returns the extracted text data from tables in the document.\n",
        "\n",
        "      This method calls `extract_tables_and_text` to get the raw text from tables,\n",
        "      then cleans the text by normalizing spaces and removing excessive newlines.\n",
        "\n",
        "      Returns:\n",
        "          List[str]: A list of cleaned strings, each representing the text extracted\n",
        "                    and cleaned from a single table detected in the document.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        # Log the start of the data extraction process\n",
        "        logging.info(\"Starting extracted data processing.\")\n",
        "\n",
        "        # Extract raw tables text\n",
        "        tables_text = self.extract_tables_and_text()\n",
        "\n",
        "        # Initialize an empty list to hold cleaned text data\n",
        "        answer=[]\n",
        "\n",
        "        # Iterate through each raw text extracted from tables\n",
        "        for text in tables_text:\n",
        "          # Replace multiple spaces or tabs with a single space\n",
        "          cleaned_string = re.sub(r'[ \\t]+', ' ', text)\n",
        "          cleaned_string = re.sub(r'\\n\\s*\\n', '', cleaned_string)\n",
        "          answer.append(cleaned_string)\n",
        "        logging.info(\"Completed data extraction and cleaning.\")\n",
        "        return answer\n",
        "\n",
        "      except Exception as e:\n",
        "          logging.error(\"Error in extracting data\", exc_info=True)\n",
        "          raise\n",
        "\n",
        "    def response(self, content: str) -> str:\n",
        "      \"\"\"\n",
        "      Processes the given content by formatting it into a key-value pair JSON-like structure using an AI assistant.\n",
        "\n",
        "      Args:\n",
        "          content (str): The input data that needs to be analyzed and formatted.\n",
        "\n",
        "      Returns:\n",
        "          str: The cleaned and formatted result as a JSON-like string, where keys without values are set to an empty string.\n",
        "      \"\"\"\n",
        "\n",
        "      try:\n",
        "\n",
        "        # Define the template for processing the input content\n",
        "        template = \"\"\"[INST] You are a JSON formatter. Your task is to analyze the given data: {data} and return the answer strictly as JSON. \n",
        "\n",
        "        - Extract financial statements including: STANDALONE, CONSOLIDATED, Balance Sheet, and Cash Flow. \n",
        "        - Use the exact structure and format as shown in this example: \n",
        "        {{\n",
        "            \"Statement_Consolidated_finanacial_results_for_all_months\": {{\n",
        "                \"Quarter ended 31 December 2024\": {{\n",
        "                    \"Revenue from operations\": 16175.71,\n",
        "                    \"Other income\": 1301.15,\n",
        "                    \"Total income\": 17476.86,\n",
        "                    \"Cost of construction and development\": 6272.52,\n",
        "                    \"Changes in inventories of work-in-progress and finished properties\": 1275.2,\n",
        "                    \"Employee benefit expense\": 2743.89,\n",
        "                    \"Finance costs\": 874.35,\n",
        "                    \"Depreciation and amortisation expenses\": 312.6,\n",
        "                    \"Other expenses\": 3596.12,\n",
        "                    \"Total expenses\": 12524.2,\n",
        "                    \"Profit/loss before tax and share of profit/loss of joint ventures\": 4952.66,\n",
        "                    \"Share of profit/loss of joint ventures, net\": 11.2,\n",
        "                    \"Profit/loss before tax\": 4941.42,\n",
        "                    \"Current tax\": 277.46,\n",
        "                    \"Deferred tax\": 411.9,\n",
        "                    \"Profit/loss for the period/year\": 4252.06,\n",
        "                    \"Other comprehensive income/loss\": 473.84,\n",
        "                    \"Total comprehensive income/loss for the period/year, net of tax\": 4725.9\n",
        "                }}\n",
        "            }}\n",
        "        }}\n",
        "\n",
        "        - Ensure that all values are positive.\n",
        "        - If a statement is not present, mark it as '<statement_name>_are_not_present'.\n",
        "        - Use precise key names like 'Employee benefit expense' instead of variations.\n",
        "        - Do not include markdown formatting, newlines, or unnecessary characters.\n",
        "        - Follow the data types (float for numeric values, string for text).\n",
        "        - Ignore any extra text that does not belong to the financial statements.\n",
        "        - If a key does not have a value, return it as an empty string.\n",
        "        - Only generate JSON for the given data. Return all answers strictly in JSON format. [/INST]\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        # template = \"\"\"[INST]you are json formatter.your task analyze the given data{data} and must return answer as json.key doest have value return empty string.only generate json for given data's.all answers should be in  json format(for all data).[/INST]\"\"\"\n",
        "\n",
        "        # Assuming PromptTemplate and LLMChain are correctly defined and imported\n",
        "        prompt = PromptTemplate(template=template, input_variables=[\"data\"])\n",
        "        llm_chain = LLMChain(prompt=prompt, verbose=True, llm=self.llm)\n",
        "        # Run the language model chain with the provided content\n",
        "        result = llm_chain.run({\"data\":content})\n",
        "        # # Clean the result by removing the pattern specified\n",
        "        # pattern = r\"\\*[^*]*\\*\"\n",
        "        # cleaned_text = re.sub(pattern, '', result)\n",
        "        # # Log the completion of the cleaning process\n",
        "        # logging.info(\"Completed processing and cleaning the response.\")\n",
        "        # print(\"result\",result)\n",
        "        return result\n",
        "\n",
        "      except Exception as e:\n",
        "          logging.error(\"Error in response\", exc_info=True)\n",
        "          raise\n",
        "\n",
        "    def list_of_answer(self) -> List[str]:\n",
        "      \"\"\"\n",
        "      Processes extracted data to generate a list of answers after further cleaning and formatting.\n",
        "\n",
        "      This method iterates over the data extracall_tables_textted by `extracted_data`, processes each item using `response`,\n",
        "      and compiles the results into a final list.\n",
        "\n",
        "      Returns:\n",
        "          List[str]: A list of strings, each a processed and cleaned response based on the extracted data.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        # Retrieve extracted data\n",
        "        answer=self.extracted_data()\n",
        "        # Initialize an empty list to hold the final processed results\n",
        "        final=[]\n",
        "        # Iterate over each item in the extracted data\n",
        "        for i in range(len(answer)):\n",
        "          print(answer[i])\n",
        "          result=self.response(answer[i])\n",
        "          final.append(result)\n",
        "        logging.info(\"Completed processing list of answers.\")\n",
        "        return final\n",
        "\n",
        "      except Exception as e:\n",
        "          logging.error(\"Error in list of answer\", exc_info=True)\n",
        "          raise\n",
        "\n",
        "    def extract_and_combine_json(self,text_list: List[str]) -> List[Dict[str, Any]]:\n",
        "      \"\"\"\n",
        "      Extracts JSON objects from a list of strings and combines them into a single list.\n",
        "\n",
        "      Each string in the input list is searched for JSON objects enclosed within ```json ... ``` markers.\n",
        "      All found JSON objects are parsed and combined into a list of dictionaries.\n",
        "\n",
        "      Args:\n",
        "          text_list: A list of strings, each potentially containing one or more JSON objects.\n",
        "\n",
        "      Returns:\n",
        "          A list of dictionaries, where each dictionary is a parsed JSON object found in the input text.\n",
        "\n",
        "      Note:\n",
        "          This function uses a specific pattern to identify JSON blocks within the text, which are enclosed in\n",
        "          triple backticks followed by 'json' keyword and assumes well-formed JSON objects.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        # This pattern matches your JSON blocks specifically formatted in your example\n",
        "        pattern = r'```json\\n({.*?})\\n```'\n",
        "        combined_json_objects = []  # This will hold all your parsed JSON objects\n",
        "\n",
        "        for text in text_list:\n",
        "            # Find all JSON strings within the text\n",
        "            json_strings = re.findall(pattern, text, re.DOTALL)\n",
        "            for json_str in json_strings:\n",
        "                try:\n",
        "                    # Parse the JSON string and append the resulting object to your list\n",
        "                    json_obj = json.loads(json_str)\n",
        "                    combined_json_objects.append(json_obj)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Failed to decode JSON: {e}\")\n",
        "        return combined_json_objects\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"Error in extract_and_combine_json {e}\")\n",
        "\n",
        "    def key_value_pair(self) -> str:\n",
        "      \"\"\"\n",
        "      Extracts JSON objects from a list of text blocks, combines them, and returns the combined JSON as a string.\n",
        "\n",
        "      This method calls `list_of_answer` to retrieve a list of text blocks, each potentially containing JSON objects.\n",
        "      These blocks are then processed by `extract_and_combine_json` to extract and combine all JSON objects into a single structure.\n",
        "      Finally, it converts this structure into a nicely formatted JSON string.\n",
        "\n",
        "      Returns:\n",
        "          A string representation of the combined JSON objects, formatted with an indent of 2 spaces.\n",
        "      \"\"\"\n",
        "      try:\n",
        "        # Retrieve the list of text blocks that may contain JSON objects\n",
        "        list_of_text=self.list_of_answer()\n",
        "        # Extract and combine JSON objects from the text blocks\n",
        "        combined_json=self.extract_and_combine_json(list_of_text)\n",
        "        # Convert the combined JSON objects into a formatted string\n",
        "        key_value=json.dumps(combined_json, indent=2)\n",
        "        logging.info(\"Successfully combined JSON objects.\")\n",
        "        return key_value\n",
        "\n",
        "      except Exception as e:\n",
        "          logging.error(f\"An error occurred in key_value_pair: {e}\")\n",
        "          raise\n",
        "      \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__==\"__main__\":\n",
        "  pdf_path=\"/media/brainwired/D/BW_ML/01_AUG_FARM_TEST/study/ExtractTheImageData/task/data (30).pdf\"\n",
        "  table=TableExtractor(pdf_path)\n",
        "  result=table.key_value_pair()\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import pytesseract\n",
        "# import re\n",
        "# import json\n",
        "# import logging\n",
        "# from pdf2image import convert_from_path\n",
        "# from typing import List, Dict, Any\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# from langchain.chains import LLMChain\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = \"YOUR_API_KEY\"\n",
        "\n",
        "# model = ChatOpenAI(model='gpt-4o')\n",
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class TableExtractor:\n",
        "    def __init__(self, pdf_path):\n",
        "        self.llm = model\n",
        "        self.pdf_path = pdf_path\n",
        "\n",
        "    def _image_list_(self) -> List[str]:\n",
        "        try:\n",
        "            images = convert_from_path(self.pdf_path, dpi=300)\n",
        "            img_list = []\n",
        "            for i, image in enumerate(images):\n",
        "                image_name = f'page_{i}.jpg'\n",
        "                image.save(image_name, 'JPEG')\n",
        "                img_list.append(image_name)\n",
        "            return img_list\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error converting PDF to images: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _preprocess_image_(self, image_path: str) -> Any:\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            denoised = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
        "            _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            return binary\n",
        "        except Exception as e:\n",
        "            logging.error(\"Error during preprocessing\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "    def _extract_text_(self, image: Any) -> str:\n",
        "        custom_config = r'--oem 3 --psm 6'\n",
        "        text = pytesseract.image_to_string(image, config=custom_config)\n",
        "        return text\n",
        "\n",
        "    def extract_and_process_text(self) -> List[str]:\n",
        "        images = self._image_list_()\n",
        "        texts = []\n",
        "        for image_path in images:\n",
        "            processed_image = self._preprocess_image_(image_path)\n",
        "            text = self._extract_text_(processed_image)\n",
        "            cleaned_text = re.sub(r'\\n+', ' ', text.strip())\n",
        "            texts.append(cleaned_text)\n",
        "        return texts\n",
        "\n",
        "    def response(self, content: str) -> str:\n",
        "        try:\n",
        "            template = \"\"\"[INST] You are a JSON formatter. Analyze the given data: {data} and return it as strictly formatted JSON. \n",
        "            - Extract financial statements including STANDALONE, CONSOLIDATED, Balance Sheet, and Cash Flow. \n",
        "            - Use this structure:\n",
        "            {{\n",
        "                \"Statement\": {{\n",
        "                    \"Quarter ended 31 December 2024\": {{\n",
        "                        \"Revenue from operations\": \"\",\n",
        "                        \"Other income\": \"\",\n",
        "                        \"Total income\": \"\",\n",
        "                        \"Profit/loss before tax\": \"\",\n",
        "                        \"Current tax\": \"\",\n",
        "                        \"Deferred tax\": \"\",\n",
        "                        \"Profit/loss for the period/year\": \"\"\n",
        "                    }}\n",
        "                }},\n",
        "                \"Balance_sheet\": \"\",\n",
        "                \"Cash_flow_statements\": \"\"\n",
        "            }}\n",
        "            - Only include data from the input. Missing data should be an empty string.\n",
        "            - Do not include any additional text or formatting. Only provide valid JSON. [/INST]\"\"\"\n",
        "\n",
        "            prompt = PromptTemplate(template=template, input_variables=[\"data\"])\n",
        "            llm_chain = LLMChain(prompt=prompt, llm=self.llm)\n",
        "            return llm_chain.run({\"data\": content})\n",
        "        except Exception as e:\n",
        "            logging.error(\"Error in response\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "    def extract_json_from_text(self, text: str) -> List[Dict[str, Any]]:\n",
        "        try:\n",
        "            pattern = r'({.*?})'\n",
        "            matches = re.findall(pattern, text, re.DOTALL)\n",
        "            json_list = []\n",
        "            for match in matches:\n",
        "                try:\n",
        "                    json_list.append(json.loads(match))\n",
        "                except json.JSONDecodeError:\n",
        "                    logging.error(f\"Failed to decode JSON: {match}\")\n",
        "            return json_list\n",
        "        except Exception as e:\n",
        "            logging.error(\"Error in extracting JSON\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "    def process_pdf(self) -> str:\n",
        "        try:\n",
        "            texts = self.extract_and_process_text()\n",
        "            final_json = []\n",
        "            for text in texts:\n",
        "                response = self.response(text)\n",
        "                extracted_json = self.extract_json_from_text(response)\n",
        "                final_json.extend(extracted_json)\n",
        "            return json.dumps(final_json, indent=2)\n",
        "        except Exception as e:\n",
        "            logging.error(\"Error in processing PDF\", exc_info=True)\n",
        "            raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import os\n",
        "import logging\n",
        "import re\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "# from langchain.document_loaders import UnstructuredPDFLoader\n",
        "import re\n",
        "import json\n",
        "from typing import List,Tuple,Any,Union,Dict\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['page_0.jpg', 'page_1.jpg', 'page_2.jpg', 'page_3.jpg', 'page_4.jpg', 'page_5.jpg', 'page_6.jpg', 'page_7.jpg', 'page_8.jpg']\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGv8WZpEePtC"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'TableExtractor' object has no attribute 'key_value_pair'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m pdf_path=\u001b[33m\"\u001b[39m\u001b[33m/media/brainwired/D/BW_ML/01_AUG_FARM_TEST/study/ExtractTheImageData/task/data (30).pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m table=TableExtractor(pdf_path)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result=\u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkey_value_pair\u001b[49m()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
            "\u001b[31mAttributeError\u001b[39m: 'TableExtractor' object has no attribute 'key_value_pair'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
